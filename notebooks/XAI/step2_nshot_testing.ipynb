{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the performance of the few-shot leanrning using the leave-one-out test set of each fold\n",
    "**Note**: each k and each fold is an independent training\n",
    "\n",
    "In each k and each fold we do the following to test the performance of the siamese network:\n",
    "1. Load the support set and the test set for each k and each fold \n",
    "2. Select a sample from the test set, and predict the similarity score between it with each sample in the support set\n",
    "3. Repeat 2 for all the samples from the test set\n",
    "\n",
    "Data needed for this notebook:\n",
    "\n",
    "- [n_fold_x_validation](https://zenodo.org/records/13833791/files/n_fold_x_validation.zip?download=1)\n",
    "- [refined models](https://zenodo.org/records/13833791/files/optimized_models.zip?download=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras import backend as k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.special import softmax\n",
    "from scipy.stats import entropy\n",
    "from scipy.ndimage import rotate\n",
    "from skimage.transform import resize\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# Change the parent dir to the correct dir on your machine \n",
    "# to make sure the following relative dirs to be working\n",
    "os.chdir('/data/Projects/2024_Invasive_species/Tree_Classification')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we manually take 3-shot 1 fold for example\n",
    "\n",
    "Change the follow code block to a loop to exhaust all the data partitionings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the support data and test data\n",
    "k = 3\n",
    "iii = 2\n",
    "\n",
    "support_smaples_path = f'./notebooks/data/n_fold_x_validation/{k}_shot_{iii}_fold_supp_samples.zarr'\n",
    "test_samples_path = f'./notebooks/data/n_fold_x_validation/{k}_shot_{iii}_fold_test_samples.zarr'\n",
    "\n",
    "support_samples = xr.open_zarr(support_smaples_path)\n",
    "test_samples = xr.open_zarr(test_samples_path)\n",
    "\n",
    "# support_samples\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the base and refined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Base model\n",
    "# base_model_name = 'siamese_model_CNN'\n",
    "# Uncomment this to choose the mobilenet03 model\n",
    "base_model_name = 'siamese_model_mobilenet03'\n",
    "\n",
    "### Refine model\n",
    "# refined from the CNN\n",
    "# refine_model_name = 'siamese_model_refined_CNN'\n",
    "# Uncomment this to choose the refined model from mobilenet03\n",
    "refine_model_name = 'siamese_model_refined_best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the refined model\n",
    "@keras.saving.register_keras_serializable(package=\"MyLayers\")\n",
    "class euclidean_lambda(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(euclidean_lambda, self).__init__(**kwargs)\n",
    "        self.name = 'euclidean_lambda'\n",
    "\n",
    "    def call(self, featA, featB):\n",
    "        squared = keras.ops.square(featA-featB)\n",
    "        return squared\n",
    "\n",
    "# Refined model, the model retrained using the support set\n",
    "refined_model_path = f'./optimized_models/refine_model/{k}_shot_{iii}_fold/{refine_model_name}.keras'\n",
    "refined_model = keras.saving.load_model(refined_model_path)\n",
    "\n",
    "# Base model, the model trained only using the initial data\n",
    "base_model_path = f'./optimized_models/results_training/Agu_pairs_training_v8/{base_model_name}.keras'\n",
    "base_model = keras.saving.load_model(base_model_path)\n",
    "\n",
    "refined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the classification performance\n",
    "def predict_label(gt_label, score_dic, metric=\"max\"):\n",
    "    \"\"\"\n",
    "    gt_label: ground truth label\n",
    "    score_dic: the dic that contains the predicted similarity score for each support sample\n",
    "               the key is the class label\n",
    "    metric: the metric to aggregate the similarity scores across the support samples within each class\n",
    "    \n",
    "    return:\n",
    "        result: [ifcorrect, similarity_score_of_the_target_class, predicted_class, similarity_score_of_the_predicted_class]\n",
    "    \"\"\"\n",
    "    reduced_score = {}\n",
    "           \n",
    "    for key, values in score_dic.items():\n",
    "        if metric == \"avg\": \n",
    "            reduced_score[key] = sum(values) / len(values) if values else 0\n",
    "        elif metric == \"max\":\n",
    "            reduced_score[key] = max(values) if values else 0\n",
    "        \n",
    "    largest_key = max(reduced_score, key=reduced_score.get)\n",
    "    largest_value = reduced_score[largest_key]\n",
    "    gt_label = int(gt_label)\n",
    "    \n",
    "    if gt_label==largest_key:\n",
    "        result = [1, gt_label, largest_value, largest_key, largest_value]\n",
    "    else:\n",
    "        result = [0, gt_label, reduced_score[gt_label], largest_key, largest_value]\n",
    "             \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the correctness metirc\n",
    "Correctness computes the ratio of the support samples belonging to the same class as the gt sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cor_cst(gt, score_dic, k):\n",
    "    '''\n",
    "    gt_label: ground truth label\n",
    "    score_dic: the dic that contains the predicted similarity score for each support sample\n",
    "               the key is the class label\n",
    "    '''\n",
    "    # count the top-k similarity scores and check if they have the same key as the gt\n",
    "    sim_scores_list = []\n",
    "    for key, values in score_dic.items():\n",
    "        for v in values:\n",
    "            sim_scores_list.append([int(key), v])\n",
    "    sim_scores = np.asarray(sim_scores_list)\n",
    "    sorted_indices = np.argsort(sim_scores[:, 1])\n",
    "    # get descending order\n",
    "    sorted_indices = sorted_indices[::-1]\n",
    "    sim_scores_sorted = sim_scores[sorted_indices]\n",
    "    top_k_scores = sim_scores_sorted[:k, :]\n",
    "    correctness = np.sum(top_k_scores == int(gt))/k\n",
    "    \n",
    "    # compute contrastivity\n",
    "    sim_prob_sorted = np.concatenate((sim_scores_sorted[:, 0:1], softmax(sim_scores_sorted[:, 1:2])), axis=1)\n",
    "    contrastivity_unnormalized = entropy(sim_prob_sorted[:k, 1])\n",
    "    \n",
    "    return correctness, contrastivity_unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the similarity score with each support sample and sort the similarity scores by class\n",
    "def get_similarity_score(test_X, support_samples, model):   \n",
    "    support_X = support_samples[\"X\"] / 255.0  \n",
    "    similarity_score = model.predict([test_X, support_X], verbose=0).squeeze()\n",
    "\n",
    "    # store the score into each class dic\n",
    "    unique_labels = np.unique(support_samples['Y'].values)\n",
    "    score_dic = {int(unique_label):[] for unique_label in unique_labels}\n",
    "    for j, support_Y in enumerate(support_samples['Y'].values):\n",
    "        score_dic[support_Y].append(similarity_score[j])\n",
    "    \n",
    "    return score_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute continuity\n",
    "Agument the test_X using one of the seven augmentation schemes used for pairing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add Gaussian noise to an RGB image\n",
    "def add_gaussian_noise(image, mean=0, std=25):\n",
    "    \n",
    "    non_zeros = image>0\n",
    "    # Generate Gaussian noise\n",
    "    np.random.seed(seed=42)\n",
    "    noise = np.random.normal(mean, std, image.shape)\n",
    "    \n",
    "    # Add the noise to the image\n",
    "    noisy_image = image + noise\n",
    "    \n",
    "    # Clip the image to ensure pixel values are in the range [0, 255]\n",
    "    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)*non_zeros\n",
    "    \n",
    "    # # Convert back to uint8\n",
    "    # noisy_image = noisy_image\n",
    "    \n",
    "    return noisy_image\n",
    "\n",
    "def random_crop(img, crop_size=(108, 108)):\n",
    "    assert crop_size[0] <= img.shape[0] and crop_size[1] <= img.shape[1], \"Crop size should be less than image size\"\n",
    "    w, h = img.shape[:2]\n",
    "    img = np.clip(img, 0, 255)\n",
    "    x, y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
    "    img_crop = img[y:y+crop_size[0], x:x+crop_size[1], :]   \n",
    "    img_crop = resize(img_crop, (w, h))\n",
    "    if not np.any(img_crop):\n",
    "        return img_crop\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "\n",
    "def aug_img_pair(img):\n",
    "    \"\"\"Augment a image and generate a list of augmented images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_pair : list of xr.DataArray, size 2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # randomly add gaussian noise\n",
    "    img_gaussian = img.copy()\n",
    "    img_gaussian.data = add_gaussian_noise(img_gaussian.values, mean=0, std=25)                       \n",
    "            \n",
    "    # randomly rotate img 90, 180, 270\n",
    "    img_rot = img.copy()\n",
    "    img_rot.data = np.rot90(img.values, k=rng.integers(1, 4))\n",
    "    \n",
    "    # random rotate another angle which is not 90, 180, 270\n",
    "    angle = rng.integers(1, 359)\n",
    "    while angle in {90, 180, 270}:\n",
    "        angle = rng.integers(1, 359)\n",
    "    img_ran_rot_1 = img.copy()\n",
    "    img_ran_rot_1.data = np.clip(rotate(img_ran_rot_1.values, angle, reshape=False), 0, 255)\n",
    "    \n",
    "    # random rotate and add noise\n",
    "    img_ran_rot_2 = img.copy()\n",
    "    img_ran_rot_2.data = add_gaussian_noise(img_ran_rot_2.data, mean=0, std=25) \n",
    "    img_ran_rot_2.data = np.clip(rotate(img_ran_rot_2.values, angle/2, reshape=False), 0, 255)\n",
    "    \n",
    "    # random crop\n",
    "    img_crop = img.copy()\n",
    "    img_crop.data = random_crop(img_crop.values)\n",
    "\n",
    "    # flip left-right img\n",
    "    img_flip_lr = img.isel(x=slice(None, None, -1))\n",
    "\n",
    "    # flip up-down img\n",
    "    img_flip_ud = img.isel(y=slice(None, None, -1))\n",
    "\n",
    "    img_list = [\n",
    "        img,\n",
    "        img_rot,\n",
    "        img_flip_lr,\n",
    "        img_flip_ud,\n",
    "        img_ran_rot_1,\n",
    "        img_ran_rot_2,\n",
    "        img_crop\n",
    "    ]\n",
    "    \n",
    "    return img_list\n",
    "\n",
    "\n",
    "def predict_cty(test_X, test_X_agu, support_samples, k, model):\n",
    "    support_X = support_samples[\"X\"] / 255.0 \n",
    "    support_Y = support_samples[\"Y\"].values.reshape(-1, 1)\n",
    "    index_id = np.array([i for i in range(support_X.sizes['sample'])]).reshape(-1, 1)\n",
    "    \n",
    "    # get the similarity score and sort by descending order for original test image\n",
    "    ori_similarity_score = model.predict([test_X, support_X], verbose=0)\n",
    "    ori_similarity_score = np.concatenate((index_id, ori_similarity_score, support_Y), axis=1)\n",
    "    ori_indices = np.argsort(ori_similarity_score[:, 1])\n",
    "    ori_indices = ori_indices[::-1]\n",
    "    ori_similarity_score = ori_similarity_score[ori_indices]\n",
    "    \n",
    "    # get the similarity score and sort by descending order for agumented test image\n",
    "    agu_similarity_score = model.predict([test_X_agu, support_X], verbose=0)\n",
    "    agu_similarity_score = np.concatenate((index_id, agu_similarity_score, support_Y), axis=1)\n",
    "    agu_indices = np.argsort(agu_similarity_score[:, 1])\n",
    "    agu_indices = agu_indices[::-1]\n",
    "    agu_similarity_score = agu_similarity_score[agu_indices]\n",
    "    \n",
    "    # compute continuity\n",
    "    count = 0      \n",
    "    for i in agu_indices[:k]:\n",
    "        if i in ori_indices[:k]:\n",
    "            count+=1\n",
    "    continuity = count/k\n",
    "        \n",
    "    return continuity, ori_similarity_score, agu_similarity_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the predictions results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def plot_results(test_sample, support_samples, similarity_scores, explation_scores, k, name=None):\n",
    "    \"\"\"\n",
    "    test_sample: the X and Y of the test image\n",
    "    support_samples: the X and Y of the support images\n",
    "    similarity_scores: [index, similarity_score, support_sample_classID]*lne(support images)\n",
    "    explation_scores: [correctness, contrastivity, continuity]\n",
    "    \"\"\"\n",
    "    matplotlib.rcParams.update({'font.size': 14})\n",
    "    # only predict the top-k support images\n",
    "    lable_dic = {92352972800: 'Species 11',\n",
    "                333988661248: 'Species 6',\n",
    "                394585504768: 'Species 7',\n",
    "                399601058816: 'Species 8',\n",
    "                578797953024: 'Species 10',\n",
    "                664680244048: 'Species 9'}\n",
    "    \n",
    "    # ugly normalization of Contrastivity\n",
    "    # k=3, max_Contrastivity = 1.1\n",
    "    max_Contrastivity = 1.1\n",
    "    \n",
    "    fig1, axs1 = plt.subplots(1, k+1, figsize=(4.5*(k+1), 4))\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "    ex_str = \"Correctness: \" + f\"{explation_scores[0]:.2f}, \" + \"Continuity: \" + f\"{explation_scores[2]:.2f}, \" + \"Contrastivity: \" + f\"{explation_scores[1]/max_Contrastivity:.2f} \\n\"\n",
    "    if k!=1:\n",
    "        fig1.suptitle(\"Support samples - \"+ex_str, y=1, x=0.625)\n",
    "    for i in range(k+1):\n",
    "        if i==0:\n",
    "            test_sample['X'].astype('int').plot.imshow(ax=axs1[i])\n",
    "            # ex_str = \"(cor: \" + f\"{explation_scores[0]:.2f}, \" + \"cty: \" + f\"{explation_scores[2]:.2f}, \" + \"cst: \" + f\"{explation_scores[1]:.2f})\"\n",
    "            axs1[i].set_title('Input: ' + lable_dic[int(test_sample['Y'].values)], pad=1)\n",
    "        else:\n",
    "            support_samples['X'].isel(sample=int(similarity_scores[i-1, 0])).astype('int').plot.imshow(ax=axs1[i])\n",
    "            support_label = int(support_samples['Y'].isel(sample=int(similarity_scores[i-1, 0])).values)\n",
    "            support_label = lable_dic[support_label] + ' ' + '(sim: '+ f\"{similarity_scores[i-1, 1]:.2f})\"\n",
    "            axs1[i].set_title(support_label, pad=1) \n",
    "        \n",
    "        axs1[i].set_xlabel('')\n",
    "        axs1[i].set_ylabel('')\n",
    "              \n",
    "    results_dir = Path(f'./optimized_models/refine_model/{k}_shot_{iii}_fold')/'plot_evaluations/'\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    plt.savefig(os.path.join(results_dir, f'sample_{name}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the results\n",
    "zero_shot_results = np.zeros((0, 5))\n",
    "refined_results = np.zeros((0, 5))\n",
    "print('[ifcorrect, gt_label, similarity_score_of_the_target_class, predicted_class, similarity_score_of_the_predicted_class]')\n",
    "\n",
    "zero_shot_correctness = []\n",
    "n_shot_correctness = []\n",
    "\n",
    "zero_shot_contrastivity  = []\n",
    "n_shot_contrastivity = []\n",
    "\n",
    "zero_shot_continuity  = []\n",
    "n_shot_continuity = []\n",
    "\n",
    "num_test_smaples = len(test_samples['X']['sample'])\n",
    "for j in range(num_test_smaples):\n",
    "    test_sample_j = test_samples.isel(sample=j)\n",
    "    \n",
    "    # Make the batch size as the total support_sample size\n",
    "    support_sample_size =  len(support_samples['X']['sample'])  \n",
    "    test_Y = test_sample_j['Y'].values \n",
    "    test_X = test_sample_j.expand_dims({\"sample\": support_sample_size})[\"X\"] / 255.0  \n",
    "    \n",
    "    # ### Test the base model zero-shot learning\n",
    "    # # Compute the similarity scores across classes\n",
    "    zeroshot_score_dic = get_similarity_score(test_X, support_samples, base_model)\n",
    "    \n",
    "    # # Compute the prediction results\n",
    "    zeroshot_result_j = predict_label(test_Y, zeroshot_score_dic, metric=\"avg\")\n",
    "    print(\"zero shot\", zeroshot_result_j)\n",
    "        \n",
    "    \n",
    "    ### Test the refined model for k-shot learning\n",
    "    # Compute the similarity scores across classes\n",
    "    nshot_score_dic = get_similarity_score(test_X, support_samples, refined_model)\n",
    "    \n",
    "    # Compute the prediction results\n",
    "    nshot_result_j = predict_label(test_Y, nshot_score_dic, metric=\"avg\")\n",
    "    \n",
    "    # All the results\n",
    "    print(\"k-shot\", nshot_result_j)\n",
    "    \n",
    "    # correctness, contrastivity\n",
    "    zero_shot_cor, zero_shot_cst= predict_cor_cst(test_Y, zeroshot_score_dic, k)\n",
    "    zero_shot_correctness.append(zero_shot_cor)\n",
    "    zero_shot_contrastivity.append(zero_shot_cst)\n",
    "    \n",
    "    n_shot_cor, n_shot_cst = predict_cor_cst(test_Y, nshot_score_dic, k)\n",
    "    n_shot_correctness.append(n_shot_cor)\n",
    "    n_shot_contrastivity.append(n_shot_cst)\n",
    "    \n",
    "    # All the results\n",
    "    zero_shot_results = np.vstack((zero_shot_results, zeroshot_result_j))\n",
    "    refined_results = np.vstack((refined_results, nshot_result_j))\n",
    "    \n",
    "    # Compute the continuity\n",
    "    index = np.random.randint(1, 7)\n",
    "    test_x_agu = aug_img_pair(test_sample_j['X'])[index]\n",
    "    test_X_agu = test_x_agu.expand_dims({\"sample\": support_sample_size})/255.0 \n",
    "      \n",
    "    # fig1, axs1 = plt.subplots(support_sample_size, 2, figsize=(6, 60))\n",
    "    # for i in range(support_sample_size):\n",
    "    #     test_X.isel(sample=i).plot.imshow(ax=axs1[i, 0])\n",
    "    #     test_X_agu.isel(sample=i).plot.imshow(ax=axs1[i, 1])\n",
    "        \n",
    "    zero_shot_cty, zero_ori_similarity_score, zero_agu_similarity_score = predict_cty(test_X, test_X_agu, support_samples, k, base_model)\n",
    "    zero_shot_continuity.append(zero_shot_cty)\n",
    "    \n",
    "    n_shot_cty, n_ori_similarity_score, n_agu_similarity_score  = predict_cty(test_X, test_X_agu, support_samples, k, refined_model)\n",
    "    n_shot_continuity.append(n_shot_cty)\n",
    "    \n",
    "    ### Plot the results\n",
    "    zero_shor_explanation_scores = [zero_shot_cor, zero_shot_cst, zero_shot_cty]\n",
    "    n_shot_explanation_scores = [n_shot_cor, n_shot_cst, n_shot_cty]\n",
    "    \n",
    "    plot_results(test_sample_j, support_samples, n_ori_similarity_score, n_shot_explanation_scores, k, name=j)\n",
    "     \n",
    "print(\"-\" * 20)   \n",
    "print(\"Overall accuracy of the base model\", sum(zero_shot_results[:, 0])/num_test_smaples)\n",
    "print(\"Overall accuracy of the refined model\", sum(refined_results[:, 0])/num_test_smaples) \n",
    "\n",
    "print(\"Correctness of the base model\", sum(zero_shot_correctness)/len(zero_shot_correctness))\n",
    "print(\"Correctness of the refined model\", sum(n_shot_correctness)/len(n_shot_correctness))\n",
    "\n",
    "print(\"zero shot contrastivity\", sum(zero_shot_contrastivity/max(zero_shot_contrastivity))/len(zero_shot_correctness)) \n",
    "print(\"n shot contrastivity\", sum(n_shot_contrastivity/max(n_shot_contrastivity))/len(zero_shot_correctness)) \n",
    "\n",
    "print(\"zero shot continuity\", sum(zero_shot_continuity)/len(zero_shot_correctness)) \n",
    "print(\"n shot continuity\", sum(n_shot_continuity)/len(zero_shot_correctness))\n",
    "\n",
    "gt_zero_shot = zero_shot_results[:, 1]  \n",
    "pd_zero_shot = zero_shot_results[:, 3]\n",
    "zero_shot_results = classification_report(gt_zero_shot, pd_zero_shot)\n",
    "print(\"***** zero shot results *****\")\n",
    "print(zero_shot_results)\n",
    "\n",
    "gt_n_shot = refined_results[:, 1]  \n",
    "pd_n_shot = refined_results[:, 3]\n",
    "n_shot_results = classification_report(gt_n_shot, pd_n_shot)\n",
    "cm = confusion_matrix(gt_n_shot, pd_n_shot)\n",
    "print(\"***** n shot results *****\")\n",
    "print(n_shot_results)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvSiamense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
