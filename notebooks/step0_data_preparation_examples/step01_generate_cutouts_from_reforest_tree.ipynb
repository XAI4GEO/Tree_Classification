{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from shapely.geometry import Polygon\n",
    "from geocoded_object_extractor import ObjectExtractor\n",
    "from geocoded_object_extractor.utils import hash_classname\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# supress rioxarray warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "data_dir = Path('/home/oku/Developments/XAI4GEO/data')\n",
    "regions = ['Carlos Vera Guevara', 'Carlos Vera Arteaga', 'Flora Pluas', 'Leonor Aspiazu', 'Manuel Macias', 'Nestor Macias']\n",
    "dataclasses = [\"other\", \"banana\", \"cacao\", \"citrus\", \"fruit\", \"timber\"]\n",
    "classes_path = data_dir/ 'reforestree/mapping/final_dataset.csv'\n",
    "annot = pd.read_csv(classes_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over regions\n",
    "# For each region, extract image cutouts and save to a separate zarr\n",
    "for region in regions:\n",
    "    print(region)\n",
    "    root = data_dir / f\"reforestree/tiles/{region} RGB/\"\n",
    "    rgb_filenames = [f.as_posix() for f in root.rglob(\"*.png\")]\n",
    "    rgb_filenames = rgb_filenames[:3] # DEBUG\n",
    "\n",
    "    # Find rows in annot where img_path is in rgb_filenames\n",
    "    annot_selected = annot[annot[\"img_path\"].isin([f.name for f in root.rglob(\"*.png\")])]\n",
    "\n",
    "    # If annot_selected is empty, skip the region\n",
    "    if annot_selected.empty:\n",
    "        print(f\"Skipping {region}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Hash the class names\n",
    "    annot_selected = annot_selected.rename(columns={\"group\": \"ESPECIE\"})\n",
    "    labels = annot_selected[\"ESPECIE\"].apply(hash_classname)\n",
    "    annot_selected[\"ID\"] = labels\n",
    "\n",
    "\n",
    "    # Get the bounding boxes\n",
    "    # Create a geometry column from the coordinates of the bounding boxes\n",
    "    geoms = [\n",
    "        Polygon([(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)])\n",
    "        for xmin, xmax, ymin, ymax in zip(\n",
    "            annot_selected[\"xmin\"],\n",
    "            annot_selected[\"xmax\"],\n",
    "            annot_selected[\"ymin\"],\n",
    "            annot_selected[\"ymax\"],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Extract image\n",
    "    # Final target size is 128x128 with padding\n",
    "    # At least 64x64 without padding\n",
    "    # Images will be downsampled by 6x6\n",
    "    obj_extr = ObjectExtractor(\n",
    "        images=rgb_filenames,\n",
    "        geoms=geoms,\n",
    "        labels=annot_selected[\"ESPECIE\"],\n",
    "        pixel_size=768,\n",
    "        min_pixel_size=384,\n",
    "        max_pixel_size=768,\n",
    "        encode_labels=True,\n",
    "    )\n",
    "\n",
    "    # extract the cutouts\n",
    "    labels, transform_params, crs, cutouts = obj_extr.get_cutouts()\n",
    "\n",
    "    id_species_mapping = annot_selected[['ESPECIE', 'ID']].drop_duplicates().set_index('ID')\n",
    "    id_species_mapping = id_species_mapping.to_dict(orient='index')\n",
    "    ds = xr.Dataset(\n",
    "    data_vars={\n",
    "        'X': (['sample', 'x', 'y', 'channel'], cutouts),\n",
    "        'Y': (['sample'], labels),\n",
    "        },\n",
    "        attrs=id_species_mapping\n",
    "    )\n",
    "    \n",
    "    ds = ds.chunk({'sample': 10, 'x': 768, 'y': 768, 'channel': 3})\n",
    "    ds = ds.isel(channel=range(3))\n",
    "    ds['Y'] = ds['Y'].astype(int)\n",
    "    ds.to_zarr(f\"{region}.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Zarr files from all regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/home/oku/Developments/XAI4GEO/data/reforestree/processed/larger_than_384/extracted_files')\n",
    "zarr_files = [f for f in data_dir.rglob(\"*.zarr\")]\n",
    "zarr_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over zarr files and merge them\n",
    "ds = None\n",
    "for file in zarr_files:\n",
    "    if ds is None:\n",
    "        ds = xr.open_zarr(file)\n",
    "    else:\n",
    "        ds = xr.concat([ds, xr.open_zarr(file)], dim='sample')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.chunk({'sample': 10, 'x': 768, 'y': 768, 'channel': 3})\n",
    "ds.to_zarr('/home/oku/Developments/XAI4GEO/data/reforestree/processed/larger_than_384/foresttree_largerthan_384.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 50 samples and plot\n",
    "rng = np.random.default_rng()\n",
    "ds_plot = ds.isel(sample=rng.choice(ds.sizes['sample'], 50, replace=False))\n",
    "ds_plot['X'].plot.imshow(col='sample', col_wrap=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai4geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
