{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From UAV orthomosaic and vector data labels to training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook illustrates how to generate cutouts employed to train a ML-based model from a UAV orthomosaic and a set of labels that are provided as a vector data file. Note that While we focus here on trees and extract airborne tree images with the goal of training a tree species classifier, the procedure is generic and can be applied to other objects as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object extraction is carried out by the `geocoded_object_extractor` tool provided in this repository. Uncomment and run the following cell in order to installing it and its dependencies in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd ../packages/geocoded_object_extractor && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geocoded_object_extractor import ObjectExtractor\n",
    "from geocoded_object_extractor.utils import write_cutouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the paths to the UAV orthomosaic image and the tree labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pathlib.Path('/home/oku/Developments/XAI4GEO/data/brazil_data/')\n",
    "image_path = data_path / 'original_data/PNM/PROCESSADOS/Map1_Orthomosaic_export_SatJun10172428194829.tif'\n",
    "tree_locations_path = data_path / 'Tree_location1.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the labels\n",
    "\n",
    "We start by loading the tree crown boundaries and the corresponding labels. In this example, the geometries have been created manually, using a GIS software (e.g. QGIS) to draw crown boundaries on the UAV orthomosaic, but they could have been generated automatically via an object detection model. See [this notebook](./TODO) on how to run [the DeepForest tree crown object deterction model](https://deepforest.readthedocs.io/en/latest/landing.html) on airborne imagery.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_locations = gpd.read_file(tree_locations_path)\n",
    "tree_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use the tree species (column *ESPECIE*) as labels. We first perform some data cleaning, replacing empty strings with missing values. We then select the only trees for which a species is provided - these are the ones for which we will extract cutouts from the orthomosaic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_locations['ESPECIE'] = tree_locations['ESPECIE'] \\\n",
    "    .replace(['', ' '], value=None)\n",
    "mask = tree_locations['ESPECIE'].notnull()\n",
    "tree_locations_with_labels = tree_locations[mask]\n",
    "tree_locations_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the cutouts (training data)\n",
    "\n",
    "We then move on to extract the cutouts from the UAV image using the tree crown geometries. Note that if the orthomosaic is provided as multiple tiles, we can pass the list of tile paths as input to the `ObjectExtractor` (`images=['tile_path1', 'tile_path2, ...]`). We also specify the side (in pixels) of the generated cutouts (180 here), smaller cutouts will be zero-padded to match the desired size. Finally, we convert non-numeric labels to a numeric format (0, 1, ...) by setting `encode_labels=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjectExtractor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms = tree_locations_with_labels.geometry\n",
    "labels = tree_locations_with_labels['ESPECIE']\n",
    "\n",
    "obj_extr = ObjectExtractor(\n",
    "    images=[image_path],\n",
    "    geoms=geoms,\n",
    "    labels=labels,\n",
    "    pixel_size=128,\n",
    "    max_pixel_size=128,\n",
    "    encode_labels=True\n",
    ")\n",
    "\n",
    "labels, transform_params, crs, cutouts = obj_extr.get_cutouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutouts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `get_cutouts()` returns the cutouts stacked in an array of shape (nsamples, ny, nx, nchannels), the corresponding labels, and information on the cutouts' Affine transformation parameters and CRS. The last two elements are necessary to geo-locate the cutouts extracted from the image.\n",
    "\n",
    "Let's plot out a selection of the cutouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 4  # plot 4 cutouts\n",
    "fig, ax = plt.subplots(1, num_samples, figsize=(10, 3))\n",
    "for nplot, ncutout in enumerate(range(0, len(cutouts), len(cutouts)//num_samples + 1)):\n",
    "    ax[nplot].imshow(cutouts[ncutout])\n",
    "    ax[nplot].set_axis_off()\n",
    "    ax[nplot].set_title(f'Class: {labels.iloc[ncutout]}')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the cutouts \n",
    "\n",
    "If we do not need to geo-locate the cutouts, we can drop this information and store the cutouts and their labels in a format that is suitable for multi-dimensional arrays, such as HDF5 or Zarr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Dataset and add cutouts and labels to it\n",
    "ds = xr.Dataset(\n",
    "    data_vars={\n",
    "        'X': (['sample', 'x', 'y', 'channel'], cutouts),\n",
    "        'Y': (['sample'], labels),\n",
    "    }\n",
    ")\n",
    "ds = ds.isel(channel=range(3))\n",
    "ds = ds.where(ds['Y']==1, drop=True)\n",
    "ds['Y'] = ds['Y'].astype(int)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the Dataset in Zarr format\n",
    "ds.to_zarr('./label6_mannual_palmtree.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not want to discard the geo-location of the cutouts, we can use the following utility function of the object extractor tool to save cutouts and labels as a set of GeoTIFFs. Note that the labels, together with the cutout IDs, are stored as attributes inside the GeoTIFF files: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cutouts(cutouts, crs, transform_params, outdir=\"./cutouts\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lha ./cutouts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
