{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be found in: https://zenodo.org/records/13380286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import rotate\n",
    "import dask\n",
    "dask.config.set(scheduler=\"synchronous\")\n",
    "\n",
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select files used for training\n",
    "dir_cutouts = Path(\"/home/oku/Developments/XAI4GEO/data/cleaned_data/all_cutouts\")\n",
    "list_files = [\n",
    "    \n",
    "    \"label142377591163_murumuru.zarr\",\n",
    "    \"label244751236943_tucuma.zarr\",\n",
    "    \"label174675723264_banana.zarr\",\n",
    "    \"label999240878592_cacao.zarr\",\n",
    "    \"label370414265344_fruit.zarr\",\n",
    "]\n",
    "for file in list_files:\n",
    "    data = xr.open_zarr(dir_cutouts / file)\n",
    "    print(file)\n",
    "    print(f\"shape:{data['X'].sizes}\")\n",
    "    print(f\"label:{np.unique(data['Y'].values)}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually investigate and select\n",
    "# f_invextigate = list_files[2]\n",
    "# ds_investigate = xr.open_zarr(dir_cutouts / f_invextigate)\n",
    "# print(f_invextigate)\n",
    "# # ds_investigate[\"X\"].plot.imshow(col=\"sample\", col_wrap=5)\n",
    "# ds_investigate[\"X\"].isel(sample = range(0, 50)).plot.imshow(col=\"sample\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually select cutouts to make training pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_murumuru = xr.open_zarr(dir_cutouts / \"label142377591163_murumuru.zarr\")\n",
    "ds_murumuru = ds_murumuru.isel(sample = range(13))\n",
    "ds_murumuru[\"X\"].plot.imshow(col=\"sample\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tucuma = xr.open_zarr(dir_cutouts / \"label244751236943_tucuma.zarr\")\n",
    "ds_tucuma[\"X\"].plot.imshow(col=\"sample\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_banana = xr.open_zarr(dir_cutouts / \"label174675723264_banana.zarr\")\n",
    "idx_banana = [1,5,10,13,14,15,22,27,33,38,43,45,46,49,51,55,57,59,62,70,77,78,81,91,96,101]\n",
    "ds_banana = ds_banana.isel(\n",
    "    sample=idx_banana\n",
    ")\n",
    "# shuffle in sample dimension\n",
    "ds_banana = ds_banana.sel(sample=rng.permutation(ds_banana.sample))\n",
    "ds_banana[\"X\"].plot.imshow(col=\"sample\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cacao = xr.open_zarr(dir_cutouts / \"label999240878592_cacao.zarr\")\n",
    "idx_cacao = [7,10,23,25,28,48,50,51,53,56,58,62,67,69]\n",
    "ds_cacao = ds_cacao.isel(\n",
    "    sample=idx_cacao\n",
    ")\n",
    "ds_cacao = ds_cacao.sel(sample=rng.permutation(ds_cacao.sample))\n",
    "ds_cacao['X'].plot.imshow(col=\"sample\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fruit = xr.open_zarr(dir_cutouts / \"label370414265344_fruit.zarr\")\n",
    "idx_fruit = [5,8,11,15,16,19,22,25,27,32,35,41,47,49,50,53,54]\n",
    "ds_fruit = ds_fruit.isel(\n",
    "    sample=idx_fruit\n",
    ")\n",
    "ds_fruit = ds_fruit.sel(sample=rng.permutation(ds_fruit.sample))\n",
    "ds_fruit['X'].plot.imshow(col=\"sample\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select three samples from each class, and plot\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 10))\n",
    "\n",
    "for ax, idx in zip(axes, range(3)):\n",
    "    ds_plot_murumuru = ds_murumuru.isel(sample=idx)\n",
    "    ds_plot_tucuma = ds_tucuma.isel(sample=idx)\n",
    "    ds_plot_banana = ds_banana.isel(sample=idx)\n",
    "    ds_plot_cacao = ds_cacao.isel(sample=idx)\n",
    "    ds_plot_fruit = ds_fruit.isel(sample=idx)\n",
    "    for i, ds_plot in enumerate([ds_plot_murumuru, ds_plot_tucuma, ds_plot_banana, ds_plot_cacao, ds_plot_fruit]):\n",
    "        ds_plot[\"X\"].astype(np.int64).plot.imshow(ax=ax[i])\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax[i].set_title(f\"Species {i+1}\", fontsize=20)\n",
    "        if i == 0:\n",
    "            ax[i].set_ylabel(f\"Sample {idx+1}\", fontsize=20)\n",
    "            ax[i].set_yticks([])\n",
    "            ax[i].set_xticks([])\n",
    "            ax[i].set_xlabel(\"\")\n",
    "        else:\n",
    "            ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_selected_cutouts = Path(\"/home/oku/Developments/XAI4GEO/data/cleaned_data/selected_cutouts\")\n",
    "list_files = [\n",
    "    \"label142377591163_murumuru.zarr\",\n",
    "    \"label244751236943_tucuma.zarr\",\n",
    "    \"label174675723264_banana.zarr\",\n",
    "    \"label999240878592_cacao.zarr\",\n",
    "    \"label370414265344_fruit.zarr\",\n",
    "]\n",
    "\n",
    "for ds, file in zip(\n",
    "    [ds_murumuru, ds_tucuma, ds_banana, ds_cacao, ds_fruit], list_files\n",
    "):\n",
    "    print(file)\n",
    "    print(f\"shape:{ds['X'].sizes}\")\n",
    "    print(f\"label:{np.unique(ds['Y'].values)}\")\n",
    "    ds.chunk({\"sample\": 50}).to_zarr(dir_selected_cutouts/file, mode=\"w\"\n",
    "    )\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_selected_cutouts = Path(\"/home/oku/Developments/XAI4GEO/data/cleaned_data/selected_cutouts\")\n",
    "list_files = [\n",
    "    \"label142377591163_murumuru.zarr\",\n",
    "    \"label244751236943_tucuma.zarr\",\n",
    "    \"label174675723264_banana.zarr\",\n",
    "    \"label999240878592_cacao.zarr\",\n",
    "    \"label370414265344_fruit.zarr\",\n",
    "]\n",
    "\n",
    "# Load selected cutouts\n",
    "list_ds = []\n",
    "for file in list_files:\n",
    "    ds = xr.open_zarr(dir_selected_cutouts / file)\n",
    "    list_ds.append(ds)\n",
    "\n",
    "ds_all = xr.concat(list_ds, dim=\"sample\")\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add Gaussian noise to an RGB image\n",
    "def add_gaussian_noise(image, mean=0, std=25):\n",
    "    \n",
    "    non_zeros = image>0\n",
    "    # Generate Gaussian noise\n",
    "    noise = np.random.normal(mean, std, image.shape)\n",
    "    \n",
    "    # Add the noise to the image\n",
    "    noisy_image = image + noise\n",
    "    \n",
    "    # Clip the image to ensure pixel values are in the range [0, 255]\n",
    "    noisy_image = np.clip(noisy_image, 0, 255).astype(np.int64)*non_zeros\n",
    "    \n",
    "    return noisy_image\n",
    "\n",
    "def random_crop(img_crop, crop_size=(108, 108)):\n",
    "    assert crop_size[0] <= img_crop.shape[0] and crop_size[1] <= img_crop.shape[1], \"Crop size should be less than image size\"\n",
    "    w, h = img_crop.shape[:2]\n",
    "    x, y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
    "    img_crop = img_crop[y:y+crop_size[0], x:x+crop_size[1], :]\n",
    "    img_crop = resize(img_crop, (w, h))\n",
    "    img_crop = np.clip(img_crop, 0, 255)\n",
    "    # img_crop = img_crop.astype(np.uint8)\n",
    "    return img_crop\n",
    "\n",
    "def aug_img_pair(img):\n",
    "    \"\"\"Augment a image and generate a list of augmented images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_pair : list of xr.DataArray, size 2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # randomly add gaussian noise\n",
    "    img_gaussian = img.copy()\n",
    "    img_gaussian.data = add_gaussian_noise(img_gaussian.values, mean=0, std=25)                       \n",
    "            \n",
    "    # randomly rotate img 90, 180, 270\n",
    "    img_rot = img.copy()\n",
    "    img_rot.data = np.rot90(img.values, k=rng.integers(1, 4))\n",
    "    \n",
    "    # random rotate another angle which is not 90, 180, 270\n",
    "    angle = rng.integers(1, 359)\n",
    "    while angle in {90, 180, 270}:\n",
    "        angle = rng.integers(1, 359)\n",
    "    img_ran_rot_1 = img.copy()\n",
    "    img_ran_rot_1.data = np.clip(rotate(img_ran_rot_1.values, angle, reshape=False), 0, 255)\n",
    "    \n",
    "    # random rotate and add noise\n",
    "    img_ran_rot_2 = img.copy()\n",
    "    img_ran_rot_2.data = add_gaussian_noise(img_ran_rot_2.data, mean=0, std=25) \n",
    "    img_ran_rot_2.data = np.clip(rotate(img_ran_rot_2.values, angle/2, reshape=False), 0, 255)\n",
    "    \n",
    "    # random crop\n",
    "    img_crop = img.copy()\n",
    "    img_crop.data = random_crop(img_crop.values)\n",
    "\n",
    "    # flip left-right img\n",
    "    img_flip_lr = img.isel(x=slice(None, None, -1))\n",
    "\n",
    "    # flip up-down img\n",
    "    img_flip_ud = img.isel(y=slice(None, None, -1))\n",
    "\n",
    "    img_list = [\n",
    "        img,\n",
    "        img_rot,\n",
    "        img_flip_lr,\n",
    "        img_flip_ud,\n",
    "        img_ran_rot_1,\n",
    "        img_ran_rot_2,\n",
    "        img_crop\n",
    "    ]\n",
    "    \n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_AUGMENTED = 7 # Number of augmented images plus original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_image_pairs(images_dataset, labels_dataset):\n",
    "    \"\"\"Function to generate image pairs for training\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images_dataset : image dataset\n",
    "        Xarray DataArray containing the images, can be dask array\n",
    "    labels_dataset : label dataset\n",
    "        NumPy array for simplicity\n",
    "    \"\"\"\n",
    "    labels_dataset = labels_dataset.compute()\n",
    "    unique_labels = np.unique(labels_dataset.values)\n",
    "\n",
    "    # Find the minimum number of samples\n",
    "    min_n_sample = min(\n",
    "        [\n",
    "            images_dataset.where(labels_dataset == label, drop=True).sizes[\"sample\"]\n",
    "            for label in unique_labels\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Generate a ds of augmented images\n",
    "    images_dataset_aug = None\n",
    "    for label in unique_labels:\n",
    "        imgs_curr = images_dataset.where(labels_dataset == label, drop=True)\n",
    "        imgs_curr = imgs_curr.isel(sample=range(min_n_sample))\n",
    "        list_imgs_curr_aug = []\n",
    "        for idx_img in range(min_n_sample):\n",
    "            list_imgs_curr_aug = list_imgs_curr_aug + aug_img_pair(\n",
    "                imgs_curr.isel(sample=idx_img)\n",
    "            )\n",
    "        da_curr_aug = xr.concat(list_imgs_curr_aug, dim=\"sample\")\n",
    "        ds_curr_aug = xr.Dataset({\"X\": da_curr_aug})\n",
    "        ds_curr_aug = ds_curr_aug.assign(\n",
    "            Y=xr.DataArray(np.full(da_curr_aug.sizes[\"sample\"], label), dims=\"sample\")\n",
    "        )\n",
    "        if images_dataset_aug is None:\n",
    "            images_dataset_aug = ds_curr_aug\n",
    "        else:\n",
    "            images_dataset_aug = xr.concat(\n",
    "                [images_dataset_aug, ds_curr_aug], dim=\"sample\"\n",
    "            )\n",
    "\n",
    "    # Generate all possible similar pairs indices combinations\n",
    "    pairs_idx_similar = list(combinations(range(min_n_sample * N_AUGMENTED), 2))\n",
    "    pairs_idx_dissimilar = list(\n",
    "        product(range(min_n_sample * N_AUGMENTED), range(min_n_sample * N_AUGMENTED))\n",
    "    )\n",
    "\n",
    "    label_dataset_aug = images_dataset_aug[\"Y\"].compute()\n",
    "\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        pair_images = []\n",
    "        pair_labels = []\n",
    "        # Images of current label\n",
    "        imgs_curr = images_dataset_aug.where(label_dataset_aug == label, drop=True)\n",
    "        imgs_curr = imgs_curr.expand_dims(pair=1)\n",
    "        # Make similar pairs\n",
    "        for pair in pairs_idx_similar:\n",
    "            pair_images_sim = xr.concat(\n",
    "                [\n",
    "                    imgs_curr.isel(sample=pair[0]).expand_dims(sample=1),\n",
    "                    imgs_curr.isel(sample=pair[1]).expand_dims(sample=1),\n",
    "                ],\n",
    "                dim=\"pair\",\n",
    "            )\n",
    "\n",
    "            pair_images.append(pair_images_sim)\n",
    "            pair_labels.append(1) # similar so label is 1\n",
    "\n",
    "        # Find non similar class labels\n",
    "        # To make dissimilar pairs\n",
    "        label_other = np.setdiff1d(unique_labels, label)\n",
    "        label_other = label_other[\n",
    "            label_other > label\n",
    "        ]  # Only select labels with higher value to avaoid duplicate dissimilar pairs\n",
    "        mask_da = xr.DataArray(np.isin(label_dataset_aug, label_other), dims=\"sample\")\n",
    "\n",
    "        # find labels_dataset in list label_other\n",
    "        imgs_curr_other = images_dataset_aug.where(mask_da, drop=True)\n",
    "\n",
    "        # check length of pairs_idx_dissimilar\n",
    "        labels_imgs_curr_other = imgs_curr_other[\"Y\"].compute()\n",
    "\n",
    "        # Make dissimilar pairs\n",
    "        for label_other_curr in label_other:\n",
    "            imgs_curr_other_curr = imgs_curr_other.where(\n",
    "                labels_imgs_curr_other == label_other_curr, drop=True\n",
    "            )\n",
    "            for pair in pairs_idx_dissimilar:\n",
    "                pair_images_dissim = xr.concat(\n",
    "                    [\n",
    "                        imgs_curr.isel(sample=pair[0]).expand_dims(sample=1),\n",
    "                        imgs_curr_other_curr.isel(sample=pair[1]).expand_dims(sample=1),\n",
    "                    ],\n",
    "                    dim=\"pair\",\n",
    "                )\n",
    "                pair_images.append(pair_images_dissim)\n",
    "                pair_labels.append(0)  # dissimilar so label is 0\n",
    "        \n",
    "        # Write to zarr in batches\n",
    "        ds_out = xr.concat(pair_images, dim=\"sample\")\n",
    "        ds_out = ds_out.assign(Y=([\"sample\"], pair_labels))\n",
    "        ds_out = ds_out.chunk({\"sample\": 100, \"pair\": -1, \"x\": -1, \"y\": -1, \"channel\": -1})\n",
    "        ds_out.to_zarr(f\"./all_pairs_{label.astype(int)}.zarr\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_train_image_pairs(ds_all[\"X\"].isel(sample=range(0,90,3)), ds_all[\"Y\"].isel(sample=range(0,90,3)))\n",
    "generate_train_image_pairs(ds_all[\"X\"], ds_all[\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the training pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a single zarr: training_pairs_unbalanced.zarr\n",
    "# Load the generated pairs\n",
    "list_ds=[]\n",
    "for zarr_file in Path(\".\").glob(\"all_pairs_*.zarr\"):\n",
    "# for zarr_file in zarr_list[0:3]:\n",
    "    ds = xr.open_zarr(zarr_file)\n",
    "    list_ds.append(ds)\n",
    "ds_images_pair = xr.concat(list_ds, dim=\"sample\")\n",
    "\n",
    "ds_images_pair_chunk = ds_images_pair.chunk({\"sample\": 100, \"pair\": -1, \"x\": -1, \"y\": -1, \"channel\": -1})\n",
    "ds_images_pair_chunk.to_zarr(\"./training_pairs_unbalanced.zarr\", mode=\"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_images_pair = xr.open_zarr(\"./training_pairs_unbalanced.zarr\")\n",
    "ds_images_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select similar and dissimilar pairs\n",
    "ds_images_pair_similar = ds_images_pair.where(ds_images_pair[\"Y\"].compute() == 1, drop=True)\n",
    "ds_images_pair_dissimilar = ds_images_pair.where(ds_images_pair[\"Y\"].compute() == 0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check before selection\n",
    "print(f\"similar pairs: {np.sum(ds_images_pair['Y']==1).values}\")\n",
    "print(f\"non similar pairs: {np.sum(ds_images_pair['Y']==0).values}\")\n",
    "ds_images_pair[\"Y\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select in ds_images_pair_dissimilar to make it same size as ds_images_pair_similar\n",
    "idx_select = rng.integers(\n",
    "    0,\n",
    "    ds_images_pair_dissimilar.sizes[\"sample\"],\n",
    "    size=ds_images_pair_similar.sizes[\"sample\"],\n",
    ")\n",
    "# order idx_select\n",
    "idx_select = np.sort(idx_select)\n",
    "ds_images_pair_dissimilar = ds_images_pair_dissimilar.isel(sample=idx_select, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine similar and dissimilar pairs one after the other\n",
    "ds_images_pair_balanced = xr.concat(\n",
    "    [ds_images_pair_similar, ds_images_pair_dissimilar], dim=\"sample\"\n",
    ")\n",
    "ds_images_pair_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check after selection\n",
    "print(f\"similar pairs after balancing: {np.sum(ds_images_pair_balanced['Y']==1).values}\")\n",
    "print(f\"non similar pairs after balancing: {np.sum(ds_images_pair_balanced['Y']==0).values}\")\n",
    "ds_images_pair_balanced[\"Y\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a index list\n",
    "# first shuffle within the similar and dissimilar parts\n",
    "# then mix them\n",
    "# Make sure there is every similar pair is followed by a dissimilar pair\n",
    "\n",
    "idx_similar = range(0, ds_images_pair_balanced.sizes[\"sample\"]//2) # Get similar pair idices\n",
    "idx_non_similar = range(\n",
    "    ds_images_pair_balanced.sizes[\"sample\"]//2, ds_images_pair_balanced.sizes[\"sample\"]\n",
    ") # Get dissimilar pair indices\n",
    "idx_similar_shuffled = rng.permutation(idx_similar) # Shuffle similar pair indices\n",
    "idx_non_similar_shuffled = rng.permutation(idx_non_similar) # Shuffle dissimilar pair indices\n",
    "\n",
    "# Mix the shuffled idices one after the other\n",
    "idx_mix = [\n",
    "    val for pair in zip(idx_similar_shuffled, idx_non_similar_shuffled) for val in pair\n",
    "]\n",
    "idx_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder ds_images_pair in sample dimension, make similar and dissimilar pairs one after the other\n",
    "ds_images_pair_balanced_shuffled = ds_images_pair_balanced.isel(sample=idx_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of similar and dissimilar pairs in the first and second half of dataset\n",
    "half_size = ds_images_pair_similar.sizes[\"sample\"]\n",
    "print(\n",
    "    f\"similar pairs first half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size))==1).values}\"\n",
    ")\n",
    "print(\n",
    "    f\"non similar pairs first half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size))==0).values}\"\n",
    ")\n",
    "print(\n",
    "    f\"similar pairs second half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size, half_size*2))==1).values}\"\n",
    ")\n",
    "print(\n",
    "    f\"non similar pairs first half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size, half_size*2))==0).values}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radomly plot 10 similar pairs\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ds_plot_similar = ds_images_pair_balanced_shuffled.where(\n",
    "    ds_images_pair_balanced_shuffled[\"Y\"].compute() == 1, drop=True\n",
    ")\n",
    "idx_sel = rng.integers(0, ds_plot_similar.sizes[\"sample\"], size=10)\n",
    "ds_plot = ds_plot_similar.isel(sample=idx_sel)\n",
    "fig, axs = plt.subplots(10, 2, figsize=(10, 60))\n",
    "for i in range(10):\n",
    "    ds_plot[\"X\"].isel(sample=i, pair=0).astype(\"int\").plot.imshow(ax=axs[i, 0])\n",
    "    ds_plot[\"X\"].isel(sample=i, pair=1).astype(\"int\").plot.imshow(ax=axs[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radomly plot 10 non-similar pairs\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ds_plot_dissimilar = ds_images_pair_balanced_shuffled.where(\n",
    "    ds_images_pair_balanced_shuffled[\"Y\"].compute() == 0, drop=True\n",
    ")\n",
    "idx_sel = rng.integers(0, ds_plot_dissimilar.sizes[\"sample\"], size=10)\n",
    "ds_plot = ds_plot_dissimilar.isel(sample=idx_sel)\n",
    "fig, axs = plt.subplots(10, 2, figsize=(10, 60))\n",
    "for i in range(10):\n",
    "    ds_plot[\"X\"].isel(sample=i, pair=0).astype(\"int\").plot.imshow(ax=axs[i, 0])\n",
    "    ds_plot[\"X\"].isel(sample=i, pair=1).astype(\"int\").plot.imshow(ax=axs[i, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "# ds_images_pair_balanced_shuffled = ds_images_pair_balanced_shuffled.chunk(\n",
    "#     {\"sample\": 500, \"pair\": -1, \"y\": -1, \"x\": -1, \"channel\": -1}\n",
    "# )\n",
    "# ds_images_pair_balanced_shuffled.to_zarr(\"./traing_pairs.zarr\", mode=\"w\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (When limited memory) Save the dataset in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2000\n",
    "for i in range(0, ds_images_pair_balanced_shuffled.sizes[\"sample\"], batch):\n",
    "    idx_end = min(i + batch, ds_images_pair_balanced_shuffled.sizes[\"sample\"])\n",
    "    ds_out = ds_images_pair_balanced_shuffled.isel(sample=range(i, idx_end)).compute()\n",
    "    ds_out = ds_out.chunk({\"sample\": 500, \"pair\": -1, \"y\": -1, \"x\": -1, \"channel\": -1})\n",
    "    xr.unify_chunks(ds_out)\n",
    "    ds_out = ds_out.chunk({\"sample\": 500, \"pair\": -1, \"y\": -1, \"x\": -1, \"channel\": -1})\n",
    "    ds_out.to_zarr(f\"training_pairs_parts/training_pairs_{i}.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into one zarr\n",
    "list_ds = []\n",
    "for zarr_file in Path(\"./training_pairs_parts\").glob(\"training_pairs_*.zarr\"):\n",
    "    ds = xr.open_zarr(zarr_file)\n",
    "    list_ds.append(ds)\n",
    "ds_images_pair_balanced_shuffled = xr.concat(list_ds, dim=\"sample\")\n",
    "ds_images_pair_balanced_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again before saving\n",
    "half_size = ds_images_pair_balanced_shuffled.sizes[\"sample\"]//2\n",
    "print(\n",
    "    f\"similar pairs first half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size))==1).values}\"\n",
    ")\n",
    "print(\n",
    "    f\"non similar pairs first half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size))==0).values}\"\n",
    ")\n",
    "print(\n",
    "    f\"similar pairs second half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size, half_size*2))==1).values}\"\n",
    ")\n",
    "print(\n",
    "    f\"non similar pairs first half: {np.sum(ds_images_pair_balanced_shuffled['Y'].isel(sample=range(half_size, half_size*2))==0).values}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_images_pair_balanced_shuffled = ds_images_pair_balanced_shuffled.chunk({\"sample\": 500, \"pair\": -1, \"y\": -1, \"x\": -1, \"channel\": -1})\n",
    "ds_images_pair_balanced_shuffled.to_zarr(\"./training_pairs.zarr\", mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai4geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
