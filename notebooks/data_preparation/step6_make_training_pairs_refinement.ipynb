{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training pairs for refinment training\n",
    "\n",
    "This step makes training data for the refinement training. \n",
    "\n",
    "It takes data in `few_shot_learning`, which can be retrieved from the link below:\n",
    "\n",
    "- `few_shot_learning`: [link](https://zenodo.org/records/13833791/files/few_shot_learning.zip?download=1)\n",
    "\n",
    "The output of this step is available on Zonodo:\n",
    "\n",
    " - `n_fold_x_validation`: [link](https://zenodo.org/records/13833540/files/n_fold_x_validation.zip?download=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import combinations, product, combinations_with_replacement\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.ndimage import rotate\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# Change the parent dir to the correct dir on your machine \n",
    "# to make sure the following relative dirs to be working\n",
    "os.chdir('/data/Projects/2024_Invasive_species/Tree_Classification')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So far, just use the selected cutout samples to counterbalance the unevenly distributed samples across all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cutouts_selected = Path(\"./notebooks/data_agu/selected_cutouts\")\n",
    "\n",
    "ds_label0 = xr.open_zarr(path_cutouts_selected / \"label142377591163_murumuru.zarr\")\n",
    "ds_label1 = xr.open_zarr(path_cutouts_selected / \"label244751236943_tucuma.zarr\")\n",
    "ds_label2 = xr.open_zarr(path_cutouts_selected / \"label174675723264_banana.zarr\")\n",
    "ds_label3 = xr.open_zarr(path_cutouts_selected / \"label999240878592_cacao.zarr\")\n",
    "ds_label5 = xr.open_zarr(path_cutouts_selected / \"label370414265344_fruit.zarr\")\n",
    "\n",
    "ds_all_base = xr.concat([ds_label0, ds_label1, ds_label2, ds_label3, ds_label5], dim='sample')\n",
    "ds_all_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the test samples for few-shot learning\n",
    "The data for the few shot learning is stored in \n",
    "\n",
    "'./notebooks/step0_data_preparation_examples/n_shots_learning/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = Path('./notebooks/data_agu/few_shot_learning')\n",
    "test_ds_path = os.path.join(test_data_path, 'Tree_labels_merged', 'tree_labels_merged.zarr')\n",
    "test_ds = xr.open_zarr(test_ds_path)\n",
    "test_ds = test_ds.compute() # Load data into memory since it's small\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the cutouts, trying to reduce the bias in terms of the correlation between canopy size and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species_ids = np.unique(test_ds['Y'].values)\n",
    "unique_species_names = [test_ds.attrs[str(id)]['ESPECIE'] for id in unique_species_ids]\n",
    "\n",
    "for id, name in zip(unique_species_ids, unique_species_names):\n",
    "    ds_species = test_ds.where(test_ds['Y']==id,drop=True)\n",
    "    if ds_species.sizes['sample'] > 5:\n",
    "        ds_species = ds_species.sel(x=slice(64,192),y=slice(64,192))\n",
    "\n",
    "        for i in range(ds_species.sizes['sample']):\n",
    "            ds_i = ds_species.isel(sample=i)\n",
    "            cutout = ds_i['X']\n",
    "            cutout.values = np.clip(cutout.values, 0, 255)\n",
    "\n",
    "            # Get the size of non zero part\n",
    "            coutout_nonzero = cutout.values\n",
    "            coutout_nonzero = coutout_nonzero[~(coutout_nonzero == 0).all(axis=(0, 2))]\n",
    "            idx = np.nonzero(~((coutout_nonzero == 0).all(axis=(0,2))))\n",
    "            coutout_nonzero = coutout_nonzero[:, idx[0], :]\n",
    "            x_size = coutout_nonzero.shape[0]\n",
    "            y_size = coutout_nonzero.shape[1]\n",
    "\n",
    "            if x_size < 64 and y_size < 64:\n",
    "                # Select the non zero part in cutout\n",
    "                cutout = cutout.isel(x=range(64-int(x_size/2),64+int(x_size/2)),y=range(64-int(y_size/2),64+int(y_size/2)))\n",
    "\n",
    "                # Interpolate the non zero part to 64x64 pixels\n",
    "                cutout = cutout.interp(x=np.linspace(cutout.x.min(), cutout.x.max(), 64),y=np.linspace(cutout.y.min(), cutout.y.max(), 64))\n",
    "\n",
    "                # Reset the x and y coordinates to 0-64\n",
    "                cutout['x'] = range(32,96)\n",
    "                cutout['y'] = range(32,96)\n",
    "\n",
    "                # Pad the interpolated image to 128x128 pixels with zeros\n",
    "                cutout = cutout.interp(x=range(0,128),y=range(0,128), kwargs={'fill_value':0})\n",
    "\n",
    "                # update ds_i\n",
    "                ds_i['X'] = cutout\n",
    "            \n",
    "            if i==0:\n",
    "                ds_output = ds_i\n",
    "            else:\n",
    "                ds_output = xr.concat([ds_output, ds_i], dim='sample')\n",
    "        \n",
    "        name = name.replace(' ', '_')\n",
    "        ds_output.to_zarr(test_data_path / 'Tree_labels_merged' / f'{id}_{name}.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = Path(os.path.join(test_data_path, 'Tree_labels_merged'))\n",
    "test_file_list = list(test_file_path.glob('*.zarr'))\n",
    "test_file_list.sort()\n",
    "# remove the non-filtered .zarr\n",
    "test_file_list = test_file_list[:-1]\n",
    "\n",
    "test_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_cutouts in test_file_list:\n",
    "    data = xr.open_zarr(f_cutouts)\n",
    "    print(f_cutouts)\n",
    "    print(f\"shape:{data['X'].sizes}\")\n",
    "    print(f\"label:{np.unique(data['Y'].values)}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the smallest number of samples across the test tree species is 6\n",
    "# we set the random maximum size to 6 \n",
    "M = 6\n",
    "select_balanced_data_list  = []\n",
    "for f_cutouts in test_file_list:\n",
    "    data = xr.open_zarr(f_cutouts)\n",
    "    selected_samples = rng.integers(0, data.sizes[\"sample\"], size=M)\n",
    "    select_balanced_data_list.append(data.isel(sample=selected_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partitioning the test data for few-shot learning with n-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_fold_cross_idx(k, M):\n",
    "    support_idx_list = []\n",
    "    test_idx_list = []\n",
    "    # Initialize KFold with N folds\n",
    "    idx = np.arange(M)\n",
    "    # umcomment the following line to shuffle the order\n",
    "    # kf = KFold(n_splits=N, shuffle=True, random_state=1) \n",
    "    # fix the order\n",
    "    kf = KFold(n_splits=int(M/k), shuffle=False)\n",
    "    # Iterate through each fold\n",
    "    for fold, (test_idx, support_idx) in enumerate(kf.split(idx)):\n",
    "        support_idx_list.append(support_idx)\n",
    "        test_idx_list.append(test_idx)\n",
    "    return support_idx_list, test_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_class_k_shot(data_list, k, M=6):\n",
    "    \n",
    "    # save the data samples as a list for each fold\n",
    "    # in total, there are int(int(M/k)) folds for a given k\n",
    "    support_sets = [[] for i in range(int(M/k))]\n",
    "    test_sets = [[] for i in range(int(M/k))]\n",
    "    \n",
    "    # get the n-fold cross-validation indexing\n",
    "    support_idx_list, test_idx_list =  n_fold_cross_idx(k, M)\n",
    "    \n",
    "    for i, (support_idx, test_idx) in enumerate(zip(support_idx_list, test_idx_list)):\n",
    "        \n",
    "        for data in data_list:\n",
    "            support_set = data.isel(sample=support_idx)\n",
    "            support_sets[i].append(support_set)\n",
    "            test_set = data.isel(sample=test_idx)\n",
    "            test_sets[i].append(test_set)\n",
    "            print(f\"Fold {i + 1}:\")\n",
    "            print(f\"Support indices: {support_idx}\")\n",
    "            print(f\"Test indices: {test_idx}\")\n",
    "            print(f\"support_set shape:{support_set['X'].sizes}\")\n",
    "            print(f\"support_set label:{np.unique(support_set['Y'].values)}\")           \n",
    "            print(f\"test_set shape:{test_set['X'].sizes}\")\n",
    "            print(f\"test_set label:{np.unique(test_set['Y'].values)}\")            \n",
    "            print(\"-\" * 20)\n",
    "        \n",
    "        # concatenate the samples across each class    \n",
    "        support_sets[i] = xr.concat(support_sets[i], dim='sample')\n",
    "        test_sets[i] = xr.concat(test_sets[i], dim='sample')\n",
    "    \n",
    "    return support_sets, test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add Gaussian noise to an RGB image\n",
    "def add_gaussian_noise(image, mean=0, std=25):\n",
    "    \n",
    "    non_zeros = image>0\n",
    "    # Generate Gaussian noise\n",
    "    np.random.seed(seed=42)\n",
    "    noise = np.random.normal(mean, std, image.shape)\n",
    "    \n",
    "    # Add the noise to the image\n",
    "    noisy_image = image + noise\n",
    "    \n",
    "    # Clip the image to ensure pixel values are in the range [0, 255]\n",
    "    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)*non_zeros\n",
    "    \n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(img, crop_size=(108, 108)):\n",
    "    assert crop_size[0] <= img.shape[0] and crop_size[1] <= img.shape[1], \"Crop size should be less than image size\"\n",
    "    w, h = img.shape[:2]\n",
    "    img = np.clip(img, 0, 255)\n",
    "    x, y = np.random.randint(h-crop_size[0]), np.random.randint(w-crop_size[1])\n",
    "    img_crop = img[y:y+crop_size[0], x:x+crop_size[1], :]   \n",
    "    img_crop = resize(img_crop, (w, h))\n",
    "    if not np.any(img_crop):\n",
    "        return img_crop\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_img_pair(img):\n",
    "    \"\"\"Augment a image and generate a list of augmented images\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_pair : list of xr.DataArray, size 2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _type_\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    # randomly add gaussian noise\n",
    "    img_gaussian = img.copy()\n",
    "    img_gaussian.data = add_gaussian_noise(img_gaussian.values, mean=0, std=25)                       \n",
    "            \n",
    "    # randomly rotate img 90, 180, 270\n",
    "    img_rot = img.copy()\n",
    "    img_rot.data = np.rot90(img.values, k=rng.integers(1, 4))\n",
    "    \n",
    "    # random rotate another angle which is not 90, 180, 270\n",
    "    angle = rng.integers(1, 359)\n",
    "    while angle in {90, 180, 270}:\n",
    "        angle = rng.integers(1, 359)\n",
    "    img_ran_rot_1 = img.copy()\n",
    "    img_ran_rot_1.data = np.clip(rotate(img_ran_rot_1.values, angle, reshape=False), 0, 255)\n",
    "    \n",
    "    # random rotate and add noise\n",
    "    img_ran_rot_2 = img.copy()\n",
    "    img_ran_rot_2.data = add_gaussian_noise(img_ran_rot_2.data, mean=0, std=25) \n",
    "    img_ran_rot_2.data = np.clip(rotate(img_ran_rot_2.values, angle/2, reshape=False), 0, 255)\n",
    "    \n",
    "    # random crop\n",
    "    img_crop = img.copy()\n",
    "    img_crop.data = random_crop(img_crop.values)\n",
    "\n",
    "    # flip left-right img\n",
    "    img_flip_lr = img.isel(x=slice(None, None, -1))\n",
    "\n",
    "    # flip up-down img\n",
    "    img_flip_ud = img.isel(y=slice(None, None, -1))\n",
    "\n",
    "    img_list = [\n",
    "        img,\n",
    "        img_rot,\n",
    "        img_flip_lr,\n",
    "        img_flip_ud,\n",
    "        img_ran_rot_1,\n",
    "        img_ran_rot_2,\n",
    "        img_crop\n",
    "    ]\n",
    "    \n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similar_pair(imgs_curr, pair=None):\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    # Make two lists list_img1 and list_img2\n",
    "    # Each contains the original and augmented images of one image in the pair\n",
    "    list_img1_img2 = []\n",
    "    for idx in [0, 1]: # augment the image 0 and 1\n",
    "        # original image\n",
    "        if pair is not None:\n",
    "            if idx == 0:\n",
    "                img = imgs_curr.isel(sample=pair[idx])\n",
    "            else:\n",
    "                img = imgs_curr.isel(sample=pair[idx])\n",
    "                img.values = add_gaussian_noise(img.values, mean=0, std=25)\n",
    "                img.data = np.rot90(img.values, k=rng.integers(1, 4))\n",
    "                \n",
    "        else:\n",
    "            if idx == 0:\n",
    "                img = imgs_curr.isel(sample=0)\n",
    "            # Add noise to slightly corrupt the image to make a psudo new image\n",
    "            else:\n",
    "                img = imgs_curr.isel(sample=0)\n",
    "                img.values = add_gaussian_noise(img.values, mean=0, std=25)\n",
    "                img.data = np.rot90(img.values, k=rng.integers(1, 4))                           \n",
    "                \n",
    "        img_list = aug_img_pair(img)\n",
    "        list_img1_img2.append(img_list)\n",
    "    \n",
    "    list_img1 = list_img1_img2[0]\n",
    "    list_img2 = list_img1_img2[1]\n",
    "\n",
    "    # exhaustively select pairs between list_img1 and list_img2\n",
    "    pairs_idx_similar = product(range(len(list_img1)), range(len(list_img2)))\n",
    "    for pair_similar in pairs_idx_similar:\n",
    "        curr_pair = xr.concat(\n",
    "            [\n",
    "                list_img1[pair_similar[0]],\n",
    "                list_img2[pair_similar[1]],\n",
    "            ],\n",
    "            dim=\"pair\",\n",
    "        )\n",
    "        curr_pair = curr_pair.expand_dims(sample=1)\n",
    "        pair_images.append(curr_pair)\n",
    "        pair_labels.append(1)\n",
    "    print('number of pairs positive samples', len(pair_labels))   \n",
    "    return pair_images, pair_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dissimilar_pair(imgs_curr, imgs_curr_other):\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    ### Add the agumentations to imgs_curr and imgs_curr_other\n",
    "    imgs_curr.sizes[\"sample\"]\n",
    "    imgs_curr_other.sizes[\"sample\"]\n",
    "    \n",
    "    list_imgs_curr_aug = []\n",
    "    list_imgs_curr_other_aug = []\n",
    "    \n",
    "    for i in range(imgs_curr.sizes[\"sample\"]):\n",
    "        list_imgs_curr_aug = list_imgs_curr_aug + aug_img_pair(\n",
    "                imgs_curr.isel(sample=i)\n",
    "            )\n",
    "    imgs_curr = xr.concat(list_imgs_curr_aug, dim=\"sample\")\n",
    "        \n",
    "    for i in range(imgs_curr_other.sizes[\"sample\"]):\n",
    "        list_imgs_curr_other_aug = list_imgs_curr_other_aug + aug_img_pair(\n",
    "                imgs_curr_other.isel(sample=i)\n",
    "            )\n",
    "    imgs_curr_other = xr.concat(list_imgs_curr_other_aug, dim=\"sample\")\n",
    "            \n",
    "    # exhaustively select pairs between imgs_curr and imgs_curr_other\n",
    "    pairs_idx_non_similar = product(\n",
    "        range(imgs_curr.sizes[\"sample\"]), range(imgs_curr_other.sizes[\"sample\"])\n",
    "    )\n",
    "    \n",
    "    # make combinations of pairs between idx_curr and idx_curr_other\n",
    "    for pair in pairs_idx_non_similar:\n",
    "        curr_pair_diff = xr.concat(\n",
    "            [\n",
    "                imgs_curr.isel(sample=pair[0]).expand_dims(pair=1),\n",
    "                imgs_curr_other.isel(sample=pair[1]).expand_dims(pair=1),\n",
    "            ],\n",
    "            dim=\"pair\",\n",
    "        )\n",
    "        curr_pair_diff = curr_pair_diff.expand_dims(sample=1)\n",
    "        pair_images.append(curr_pair_diff)\n",
    "        pair_labels.append(0)\n",
    "    print('imgs_curr', imgs_curr.sizes[\"sample\"])\n",
    "    print('imgs_curr_other', imgs_curr_other.sizes[\"sample\"])\n",
    "    print('number of pairs negtive samples', len(pair_labels))\n",
    "    return pair_images, pair_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_refine_image_paris(support_set, base_set):\n",
    "    \"\"\"Function to generate new image pairs for the k-shot learning\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    support_set: the dataset contains the support samples of images and labels of the \n",
    "        Xarray DataArray \n",
    "    labels_dataset: the dataset contains the original samples of images and labels of the\n",
    "        Xarray DataArray\n",
    "    \"\"\"\n",
    "    support_labels = support_set['Y'].compute()\n",
    "    support_iamges = support_set['X']\n",
    "    unique_support_labels = np.unique(support_labels.values)\n",
    "    \n",
    "    # Get the combined datasets\n",
    "    combined_set = xr.concat([support_set, base_set], dim=\"sample\")\n",
    "    combined_images = combined_set['X']\n",
    "    combined_labels = combined_set['Y'].compute()\n",
    "    unique_combined_labels = np.unique(combined_labels.values)\n",
    "    \n",
    "    \n",
    "    # Find the minimum number of samples\n",
    "    min_n_sample = min(\n",
    "        [\n",
    "            support_labels.where(support_labels == label, drop=True).sizes[\"sample\"]\n",
    "            for label in support_labels\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "     \n",
    "    # Only loop the unique_support_labels to avoid repetative pairing from the base_set\n",
    "    for label in unique_support_labels:\n",
    "        # Images of current label\n",
    "        imgs_curr = support_iamges.where(support_labels == label, drop=True)\n",
    "\n",
    "        # select first min_n_sample samples for each label\n",
    "        # this step is not necessary because in the support set the samples across classes are balanced\n",
    "        imgs_curr = imgs_curr.isel(sample=range(min_n_sample))\n",
    "\n",
    "        # Find non similar class labels\n",
    "        # To make dissimilar pairs\n",
    "        # A dissimilar image can come from the base_set or the other images from the support_set\n",
    "        # Therefore, here we use the unique_combined_labels \n",
    "        label_other = np.setdiff1d(unique_combined_labels, label)\n",
    "        mask_da = xr.DataArray(np.isin(combined_labels, label_other), dims=\"sample\")\n",
    "\n",
    "        # find labels_dataset in list label_other\n",
    "        imgs_curr_other = combined_images.where(mask_da, drop=True)\n",
    "        \n",
    "        # Generate positive pairs\n",
    "        # When there is more than one unique support sample in each class \n",
    "        if min_n_sample>=2:\n",
    "            # Generate all possible pairs\n",
    "            pairs_idx = list(combinations_with_replacement(range(min_n_sample), 2))\n",
    "            for pair in pairs_idx:\n",
    "                _pair_images_pos, _pair_labels_pos = generate_similar_pair(imgs_curr, pair=pair)\n",
    "                pair_images += _pair_images_pos\n",
    "                pair_labels += _pair_labels_pos\n",
    "        # When there is only one unique support sample in each class\n",
    "        else:\n",
    "            _pair_images_pos, _pair_labels_pos = generate_similar_pair(imgs_curr, pair=None)\n",
    "            pair_images += _pair_images_pos\n",
    "            pair_labels += _pair_labels_pos\n",
    "                     \n",
    "        # Generative negtive pairs\n",
    "        _pair_images_neg, _pair_labels_neg = generate_dissimilar_pair(imgs_curr, imgs_curr_other)\n",
    "        pair_images += _pair_images_neg\n",
    "        pair_labels += _pair_labels_neg\n",
    "     \n",
    "    return xr.concat(pair_images, dim=\"sample\"), np.array(pair_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two steps for the few-shot learning\n",
    "* Using the test set to do the zero-shot test\n",
    "* Using the support set to do the few-shot learning\n",
    "\n",
    "**Note: in this notebook, we mannually set k to 1, 2, 3 to generate all the partitioning.**\n",
    "\n",
    "Later, the finally performance results are averaged across all the folds within each k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairing\n",
    "k = 1\n",
    "support_sets, test_sets = n_class_k_shot(select_balanced_data_list, k)\n",
    "print(f\"{len(support_sets)} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some of the pairs\n",
    "def shuffle_pairs(ds_images_pair, npair=10, plot_examples=True):\n",
    "    idx_similar = range(0, ds_images_pair.sizes['sample']//2)\n",
    "    idx_non_similar = range(ds_images_pair.sizes['sample']//2, ds_images_pair.sizes['sample'])\n",
    "    #shuffle the indices\n",
    "    idx_similar_shuffled = rng.permutation(idx_similar)\n",
    "    idx_non_similar_shuffled = rng.permutation(idx_non_similar)\n",
    "    idx_mix = [val for pair in zip(idx_similar_shuffled, idx_non_similar_shuffled) for val in pair]\n",
    "    \n",
    "    ds_images_pair_shuffled = ds_images_pair.isel(sample=idx_mix)\n",
    "    ds_images_pair_shuffled['X'] = ds_images_pair_shuffled['X'].fillna(0)\n",
    "    \n",
    "    if plot_examples:\n",
    "        # radomly plot 10 similar pairs\n",
    "        ds_images_pair_shuffled_similar = ds_images_pair_shuffled.where(ds_images_pair_shuffled['Y']==1, drop=True)\n",
    "        idx_sel = rng.integers(0, ds_images_pair_shuffled_similar.sizes[\"sample\"], size=10)\n",
    "        ds_plot1 = ds_images_pair_shuffled_similar.isel(sample=idx_sel)\n",
    "        fig1, axs1 = plt.subplots(10, 2, figsize=(10, 60))\n",
    "        for i in range(npair):\n",
    "            ds_plot1['X'].isel(sample=i, pair=0).astype('int').plot.imshow(ax=axs1[i, 0])\n",
    "            ds_plot1['X'].isel(sample=i, pair=1).astype('int').plot.imshow(ax=axs1[i, 1])\n",
    "            assert ds_plot1['X'].isel(sample=i, pair=0).shape[0]==ds_plot1['X'].isel(sample=i, pair=0).shape[1]==128, \"image wh is not 128\"\n",
    "            assert ds_plot1['X'].isel(sample=i, pair=1).shape[0]==ds_plot1['X'].isel(sample=i, pair=1).shape[1]==128, \"image wh is not 128\"\n",
    "                \n",
    "        # radomly plot 10 dissimilar pairs\n",
    "        ds_images_pair_shuffled_dissimilar = ds_images_pair_shuffled.where(ds_images_pair_shuffled['Y']==0, drop=True)\n",
    "        idx_sel = rng.integers(0, ds_images_pair_shuffled_dissimilar.sizes[\"sample\"], size=10)\n",
    "        ds_plot2 = ds_images_pair_shuffled_dissimilar.isel(sample=idx_sel)\n",
    "        fig2, axs2 = plt.subplots(10, 2, figsize=(10, 60))\n",
    "        for i in range(npair):\n",
    "            ds_plot2['X'].isel(sample=i, pair=0).astype('int').plot.imshow(ax=axs2[i, 0])\n",
    "            ds_plot2['X'].isel(sample=i, pair=1).astype('int').plot.imshow(ax=axs2[i, 1])\n",
    "            assert ds_plot2['X'].isel(sample=i, pair=0).shape[0]==ds_plot2['X'].isel(sample=i, pair=0).shape[1]==128, \"image wh is not 128\"\n",
    "            assert ds_plot2['X'].isel(sample=i, pair=1).shape[0]==ds_plot2['X'].isel(sample=i, pair=1).shape[1]==128, \"image wh is not 128\"\n",
    "        \n",
    "    return ds_images_pair_shuffled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the negtive and positive pairs\n",
    "def get_balanced_pairs(images_pair, labels_pair):\n",
    "    ds_images_pair = images_pair.to_dataset()\n",
    "    ds_images_pair = ds_images_pair.assign(Y = (['sample'], labels_pair))\n",
    "    \n",
    "    # select similar and dissimilar pairs\n",
    "    ds_images_pair_similar = ds_images_pair.where(ds_images_pair['Y'] == 1, drop=True)\n",
    "    ds_images_pair_dissimilar = ds_images_pair.where(ds_images_pair['Y'] == 0, drop=True)\n",
    "  \n",
    "    similar_pair_size = ds_images_pair_similar.sizes['sample']\n",
    "    dissimilar_pair_size = ds_images_pair_dissimilar.sizes['sample']\n",
    "    if similar_pair_size>=dissimilar_pair_size:\n",
    "        idx_similar = rng.integers(0, similar_pair_size, size=dissimilar_pair_size)\n",
    "        ds_images_pair_similar = ds_images_pair_similar.isel(sample=idx_similar)\n",
    "    else:\n",
    "        idx_dissimilar = rng.integers(0, dissimilar_pair_size, size=similar_pair_size)\n",
    "        ds_images_pair_dissimilar = ds_images_pair_dissimilar.isel(sample=idx_dissimilar)  \n",
    "    \n",
    "    # Combine similar and dissimilar pairs one after the other\n",
    "    ds_images_pair = xr.concat([ds_images_pair_similar, ds_images_pair_dissimilar], dim='sample')\n",
    "    \n",
    "    print(f\"similar pairs: {np.sum(ds_images_pair['Y']==1).values}\")\n",
    "    print(f\"non similar pairs: {np.sum(ds_images_pair['Y']==0).values}\")\n",
    "    \n",
    "    return ds_images_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(support_sets)):\n",
    "    print(f\"{i+1}/{len(support_sets)} fold, {k}-shot learning\")\n",
    "    \n",
    "    ##---- support samples ----##\n",
    "    support_set = support_sets[i] \n",
    "    support_set['X'] = support_set['X'].fillna(0)\n",
    "    support_set = support_set.chunk({'sample': 500, 'y': -1, 'x': -1, 'channel': -1})\n",
    "    support_set.to_zarr(f'./notebooks/data_agu/n_fold_x_validation/{k}_shot_{i+1}_fold_supp_samples.zarr', mode=\"w\")\n",
    "    support_set\n",
    "     \n",
    "    ##---- test samples ----##\n",
    "    # Save corresponding leave-one-out test set for each fold\n",
    "    test_set = test_sets[i]\n",
    "    test_set['X'] = test_set['X'].fillna(0)\n",
    "    test_set = test_set.chunk({'sample': 500, 'y': -1, 'x': -1, 'channel': -1})\n",
    "    test_set.to_zarr(f'./notebooks/data_agu/n_fold_x_validation/{k}_shot_{i+1}_fold_test_samples.zarr', mode=\"w\")\n",
    "    test_set\n",
    "    \n",
    "    ##---- Pairing ----##\n",
    "    # Get all the pairs with respect to the support dataset\n",
    "    # The pairs within the base set are not considered any more \n",
    "    # meaning that at least one image is from the support set in each generated pair\n",
    "    images_pair, labels_pair = generate_refine_image_paris(support_set, ds_all_base)\n",
    "    \n",
    "    # # Balance the positive and negtive pairs, and shuffle the pairs\n",
    "    ds_images_pair = get_balanced_pairs(images_pair, labels_pair)    \n",
    "    print(\"-\" * 20)    \n",
    "    ds_images_pair_shuffled = shuffle_pairs(ds_images_pair, npair=10)\n",
    "    \n",
    "    ## Save the data for the few-shot learning\n",
    "    ds_images_pair_shuffled.to_zarr(f'./notebooks/data_agu/n_fold_x_validation/{k}_shot_{i+1}_fold_supp_pairs.zarr', mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvSiamense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
