{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We retrain the model using the support set to do the few-shot learning\n",
    "**Note: each k and each fold is an independent training.**\n",
    "\n",
    "For example, in our experiment, we have 6 smaples in each class for the few-shot learning.\n",
    "\n",
    "The data partitioning is listed below for 1-, 2-, 3-shot learning.\n",
    "\n",
    "In total, we have 11 independent trained models. \n",
    "\n",
    "Meaning that, in each trained model, the support and test samples are different. The model never sees the test smaples. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| K shot | \\#Samples in supp. set | \\#Samples in test set     | \\#Folds  | \n",
    "| :---   |    :----:              |        :----:             | :----:   | \n",
    "| 1      | 1                      | 5                         | 6/1=6    | \n",
    "| 2      | 2                      | 4                         | 6/2=3    |\n",
    "| 3      | 3                      | 3                         | 6/3=2    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data needed for this notebook is available on Zenodo:\n",
    "- [n_fold_x_validation](https://zenodo.org/records/13833791/files/n_fold_x_validation.zip?download=1)\n",
    "\n",
    "The output of this notebook, which the refined model, is available on Zenodo:\n",
    "- [optimized_models](https://zenodo.org/records/13833791/files/optimized_models.zip?download=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras import backend as k\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "\n",
    "# Change the parent dir to the correct dir on your machine \n",
    "# to make sure the following relative dirs to be working\n",
    "os.chdir('/data/Projects/2024_Invasive_species/Tree_Classification')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, we mannually set k and iii for k-shot learning in the iii fold, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the support dataset \n",
    "# Here we take 3-shot 1 fold for example\n",
    "# Change this to a loop to exhaust all the data partitioning \n",
    "k = 1\n",
    "iii = 6\n",
    "support_path = f'./notebooks/data_agu/n_fold_x_validation/{k}_shot_{iii}_fold_supp_pairs.zarr'\n",
    "support_set = xr.open_zarr(support_path)\n",
    "support_set\n",
    "\n",
    "images_pair = support_set[\"X\"].to_numpy()/255 # Scale to [0, 1]\n",
    "labels_pair = support_set[\"Y\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shallow CNN model\n",
    "base_model_name = 'CNN'\n",
    "# Uncomment this to choose the mobilenet03 model\n",
    "# base_model_name = 'mobilenet03'\n",
    "base_model_dir = f'./optimized_models/results_training/Agu_pairs_training_v8/siamese_model_{base_model_name}.keras'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable(package=\"MyLayers\")\n",
    "class euclidean_lambda(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(euclidean_lambda, self).__init__(**kwargs)\n",
    "        self.name = 'euclidean_lambda'\n",
    "\n",
    "    def call(self, featA, featB):\n",
    "        squared = keras.ops.square(featA-featB)\n",
    "        return squared\n",
    "\n",
    "model = keras.saving.load_model(base_model_dir)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the refinement training\n",
    "# Compile model\n",
    "lr_init = 2.5e-05 # initial learning rate\n",
    "metrics = [keras.metrics.BinaryAccuracy(threshold=0.5)]    \n",
    "opt = keras.optimizers.Adam(learning_rate=lr_init)\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "# Configure training  \n",
    "train_name = f'{k}_shot_{iii}_fold/'  \n",
    "dir_training = Path(\"./optimized_models/refine_model/\") / train_name\n",
    "dir_training.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, metrics):\n",
    "    \"\"\"\n",
    "    Plot the training history\n",
    "\n",
    "    Args:\n",
    "        history (keras History object that is returned by model.fit())\n",
    "        metrics (str, list): Metric or a list of metrics to plot\n",
    "    \"\"\"\n",
    "    history_df = pd.DataFrame.from_dict(history.history)\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=history_df[metrics])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"metric\")\n",
    "    plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(labels_pred, labels_pair):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    sub = fig.add_subplot(1, 2, 1)\n",
    "    sub.plot(labels_pred[labels_pair==1], '.', markersize=0.5)\n",
    "    sub.plot(labels_pair[labels_pair==1])\n",
    "\n",
    "    sub = fig.add_subplot(1, 2, 2)\n",
    "    sub.plot(labels_pred[labels_pair==0], '.', markersize=0.5)\n",
    "    sub.plot(labels_pair[labels_pair==0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_hist(labels_pred):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    counts, bins = np.histogram(labels_pred[labels_pair==1])\n",
    "    sub = fig.add_subplot(1, 2, 1)\n",
    "    sub.stairs(counts, bins)\n",
    "\n",
    "    sub = fig.add_subplot(1, 2, 2)\n",
    "    counts, bins = np.histogram(labels_pred[labels_pair==0])\n",
    "    sub.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to plot predictions every 10 epochs\n",
    "class PlotPredictionsCallback(Callback):\n",
    "    def __init__(self, x_val, y_val, dir_training):\n",
    "        super(PlotPredictionsCallback, self).__init__()\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.dir_training = dir_training\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 2 == 0:\n",
    "            \n",
    "            # Make predictions on the validation data\n",
    "            images_pair = self.x_val\n",
    "            labels_pred = self.model.predict([images_pair[:,0], images_pair[:,1]])\n",
    "            \n",
    "            dir_epoch = self.dir_training / f'epoch_{epoch+1}'\n",
    "            dir_epoch.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Plots\n",
    "            plot_prediction(labels_pred, self.y_val)\n",
    "            plt.savefig(dir_epoch/'prediction.png')\n",
    "            plot_prediction_hist(labels_pred)\n",
    "            plt.savefig(dir_epoch/'prediction_hist.png')\n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callbacks\n",
    "# learning_rate_scheduler = LearningRateScheduler(lr_schedule)\n",
    "learning_rate_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "plot_pred_callback = PlotPredictionsCallback(images_pair, labels_pair, dir_training)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, start_from_epoch=5, restore_best_weights=True)\n",
    "callbacks = [learning_rate_scheduler, plot_pred_callback, earlystop]\n",
    "\n",
    "history = model.fit([images_pair[:,0], images_pair[:,1]], labels_pair[:], batch_size=4, epochs=10, validation_split=0.2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "keras.saving.save_model(model, dir_training / 'siamese_model_refined.keras', overwrite=True)\n",
    "model.save_weights(dir_training / \"optimized_weights_refined.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_training / \"history.pkl\", \"wb\") as file_pi:\n",
    "        pickle.dump(history, file_pi)\n",
    "    \n",
    "# Model evaluation plots\n",
    "model_loaded = keras.saving.load_model(dir_training / 'siamese_model_refined.keras', compile=False)\n",
    "labels_pred = model.predict([images_pair[:, 0], images_pair[:, 1]])\n",
    "plot_history(history, ['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n",
    "plt.savefig(dir_training / \"history.png\")\n",
    "plot_prediction(labels_pred, labels_pair)\n",
    "plt.savefig(dir_training / \"prediction.png\")\n",
    "plot_prediction_hist(labels_pred)\n",
    "plt.savefig(dir_training / \"prediction_hist.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnvSiamense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
