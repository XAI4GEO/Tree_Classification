{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import keras\n",
    "import dask.array as da\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "\n",
    "import dask\n",
    "dask.config.set(scheduler='synchronous') # to avoid memory issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### Steps:\n",
    "1. load data: 1) test sample; 2) class examples\n",
    "1. load the trained Siamese model\n",
    "1. pair the test sample with all class examples\n",
    "1. compute similarity scores using Siamese model\n",
    "1. perform classification based on the similarity scores:\n",
    "    - average similarity score\n",
    "    - K-nearest neighbors\n",
    "    - Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = xr.open_zarr('data/test_example_brazil.zarr/')\n",
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the test sample\n",
    "test_sample['X'].astype('int').plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_files = sorted([file for file in Path('data/example_classes/').rglob('*.zarr')])\n",
    "class_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually create a map between class text and integer label\n",
    "class_map = {0: 'banana', 1:'cacao', 2:'fruit', 3:'palmtree'}\n",
    "\n",
    "class_data={}\n",
    "for class_i in range(len(class_files)):\n",
    "    class_data[class_i] = xr.open_zarr(class_files[class_i])\n",
    "class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first three examples in each example class\n",
    "fig, axs = plt.subplots(4, 3, figsize=(15, 15))\n",
    "for class_i in range(len(class_data)):\n",
    "    for example_i in range(3):\n",
    "        class_data[class_i]['X'][example_i].astype('int').plot.imshow(ax=axs[class_i, example_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the trained Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable(package=\"MyLayers\")\n",
    "class euclidean_lambda(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(euclidean_lambda, self).__init__(**kwargs)\n",
    "        self.name = 'euclidean_lambda'\n",
    "\n",
    "    def call(self, featA, featB):\n",
    "        squared = keras.ops.square(featA-featB)\n",
    "        return squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.saving.get_custom_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = keras.models.load_model(\n",
    "    \"../optimized_models/siamese_model.keras\",\n",
    "    custom_objects = keras.saving.get_custom_objects()\n",
    ")\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to memory limit, we make a function to compute the similarity score per batch\n",
    "batch_size = 10  # number of samples to process at once to compute similarity score\n",
    "def predict_per_chunk(x, y):\n",
    "    \"\"\"Compute similarity score between two sets of images in the same bacth.\"\"\"\n",
    "    return siamese_model.predict([x, y], verbose=0).squeeze()\n",
    "\n",
    "# Compute similarity scores between the test sample and each example class\n",
    "similarity_scores = {}\n",
    "list_scores = []\n",
    "for class_i in class_map.keys():\n",
    "    \n",
    "    # Make sample and example class data pairs\n",
    "    shape = class_data[class_i][\"sample\"].shape[0]\n",
    "    X_sample_norm = test_sample.expand_dims({\"sample\": shape})[\"X\"] / 255.0\n",
    "    X_class_norm = class_data[class_i][\"X\"] / 255.0\n",
    "\n",
    "    # Chunk the data\n",
    "    X_sample_norm = X_sample_norm.chunk({\"sample\": batch_size})\n",
    "    X_class_norm = X_class_norm.chunk({\"sample\": batch_size})\n",
    "\n",
    "    # Compute similarity scores per batch\n",
    "    scores = da.map_blocks(\n",
    "        predict_per_chunk,\n",
    "        X_sample_norm.data,\n",
    "        X_class_norm.data,\n",
    "        dtype=\"float32\",\n",
    "        chunks=(batch_size,),\n",
    "        drop_axis=(1, 2, 3),\n",
    "    )\n",
    "    scores = scores.compute()\n",
    "\n",
    "    similarity_scores[class_i] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the similarity scores to piclke file\n",
    "with open('data/similarity_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(similarity_scores, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the similarity scores from pickle file\n",
    "with open('data/similarity_scores.pkl', 'rb') as f:\n",
    "    similarity_scores = pickle.load(f)\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Average similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average similarity score per example class\n",
    "average_scores = {}\n",
    "for class_i in similarity_scores.keys():\n",
    "    average_scores[class_i] = np.mean(similarity_scores[class_i])\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = class_map[np.argmax(list(average_scores.values()))]\n",
    "print(f\"Prediction by average similarity score: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metod 2: K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual input: the number of K\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top K highest similarity scores and their corresponding class\n",
    "\n",
    "# first search for the top k scores per class\n",
    "top_k_scores = {}\n",
    "for class_i in similarity_scores.keys():\n",
    "    top_k_scores[class_i] = np.sort(similarity_scores[class_i])[-k:]\n",
    "\n",
    "# Reverse the dictionary\n",
    "reversed_dict = {vi: k for k, v in top_k_scores.items() for vi in v}\n",
    "\n",
    "# then sort the top k scores from all classes and \n",
    "top_k_scores_all = np.concatenate(list(top_k_scores.values()))\n",
    "top_k_scores_all_sorted = np.sort(top_k_scores_all)[::-1][0:k]\n",
    "\n",
    "# find the class with most top k scores\n",
    "top_k_classes = [reversed_dict[key] for key in top_k_scores_all_sorted]\n",
    "counter = Counter(top_k_classes)\n",
    "most_common_value = counter.most_common(1)[0][0]\n",
    "\n",
    "print(f\"Prediction by KNN: {class_map[most_common_value]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the trained SVM and perform prediction based on statistis of similarity scores\n",
    "# Load the trained SVM model from pickle file\n",
    "with open('../optimized_models/svm_classifier.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)\n",
    "svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prediction takes mean similarity scores of each class as input\n",
    "mean_scores = np.array([average_scores[class_i] for class_i in range(len(class_map))]).reshape(1, -1)\n",
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "prediction = svm_model.predict(mean_scores)[0].astype(int)\n",
    "print(f\"Prediction by SVM: {class_map[prediction]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
